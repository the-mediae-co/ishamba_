# Generated by Django 3.2.11 on 2022-02-14 14:07

import time
import itertools
from datetime import timedelta
from django.utils.timezone import now
from django.db import migrations
from django.db.models import F, Q, Sum
from django.conf import settings

from gateways.africastalking.gateway import AfricasTalkingGateway
# from digifarm.gateways import DigifarmSMSGateway

import logging
logger = logging.getLogger(__name__)

# SMSRecipient:
# Extract the gateway_msg_id from the JSON 'extra' field if not already done
# Split extra__cost into cost (decimal) and cost_units
# Add gateway_name
# Add country (always Kenya)

# OutgoingSMSSummaries:
# Regenerate all summaries, working from most recent backwards in time


def daterange(start_date, end_date):
    """ Produce a sequence of dates (forward or backwards), inclusive of both ends """
    backwards = start_date > end_date
    delta = abs((start_date - end_date).days) + 1  # To make the dates range inclusive
    if backwards:
        seq_range = range(0, -delta, -1)
    else:
        seq_range = range(0, delta, 1)  # dates, inclusive
    for n in seq_range:
        yield start_date + timedelta(n)


def populate_new_fields(apps, schema_editor):
    schema_name = schema_editor.connection.schema_name
    at_gateway_name = AfricasTalkingGateway.Meta.verbose_name
    df_gateway_name = "Digifarm"
    gateways = [at_gateway_name, df_gateway_name]

    db_alias = schema_editor.connection.alias
    OutgoingSMS = apps.get_model("sms", "OutgoingSMS")  # NOQA
    SMSRecipient = apps.get_model("sms", "SMSRecipient")  # NOQA
    User = apps.get_model("auth", "User")  # NOQA
    DailyOutgoingSMSSummary = apps.get_model("sms", "DailyOutgoingSMSSummary")  # NOQA
    Border = apps.get_model("world", "Border")  # NOQA

    logger.setLevel(logging.DEBUG)
    settings.LOGGING['loggers']['django'] = {'level': 'DEBUG', 'handlers': ['console']}

    with schema_editor.connection.cursor() as cursor:
        # To enable batching, find the highest SMSRecipient.id value
        sql = f"SELECT id FROM {schema_name}.sms_smsrecipient ORDER BY id DESC LIMIT 1"
        cursor.execute(sql,)
        data = cursor.fetchone()
        # If there are no SMSRecipient objects in this schema, return
        if not data:
            return

        max_id = data[0]
        logger.debug(f"The highest {schema_name}.SMSRecipient.id is {max_id}")
        tic = time.perf_counter()

        # Check if any gateway_msg_id extraction is needed. If a previous run
        # of this same migration already passed this step, no need to redo it.
        count = SMSRecipient.objects.filter(Q(gateway_msg_id__isnull=True) | Q(gateway_msg_id='')).count()
        if count == 0:
            logger.debug(f"No need to extract AfricasTalking SMSRecipient gateway_msg_id from extra JSON field")
        else:
            # First, make sure all messages have their gateway_message_id set.
            # If not, extract the value from the extra JSON object properly
            chunk_size = 100000
            bottom_id = 0
            top_id = bottom_id + chunk_size

            logger.debug(f"Extracting AfricasTalking SMSRecipient gateway_msg_id from extra JSON field")

            # This works, but is SLOW. I used it in my dev environment.
            # However, on production I manually executed SQL statements in batches as follows:
            # UPDATE ishamba.sms_smsrecipient SET gateway_msg_id = extra ->> 'messageId' WHERE id IN
            #     (SELECT sub.id from ishamba.sms_smsrecipient sub WHERE sub.gateway_msg_id IS NULL
            #         AND sub.extra ->> 'messageId' IS NOT NULL
            #         AND LENGTH(sub.extra ->> 'messageId') > 0 LIMIT 500000);
            while bottom_id < max_id:
                logger.debug(f"Extracting {schema_name} AfricasTalking SMSRecipient gateway_msg_id {bottom_id:,} to {top_id:,}")
                sql = f"UPDATE {schema_name}.sms_smsrecipient " \
                      f"SET gateway_msg_id = extra ->> 'messageId' " \
                      f"WHERE (gateway_msg_id IS NULL OR LENGTH(gateway_msg_id) = 0) " \
                      f"  AND extra ->> 'messageId' IS NOT NULL " \
                      f"  AND LENGTH(extra ->> 'messageId') > 1 " \
                      f"  AND id BETWEEN {bottom_id} AND {top_id}"
                cursor.execute(sql, )
                bottom_id = top_id
                top_id = top_id + chunk_size

        toc0 = time.perf_counter()
        logger.debug(f"Extracted AfricasTalking SMSRecipient gateway_msg_ids in {toc0 - tic:0.1f} seconds")

        # Now extract the 'cost' and cost_units from Digifarm messages, and set the gateway_name.
        # These have no cost and were only in Kenya, so this is a simple 'conversion'.
        count = SMSRecipient.objects.filter(gateway_name='?', gateway_msg_id__startswith='DFid_').count()
        if count == 0:
            logger.debug(f"No need to annotate Digifarm SMSRecipient objects")
        else:
            # Similar to above, this works and was used in development, however in production
            # the following SQL was executed in batches:
            # UPDATE ishamba.sms_smsrecipient SET gateway_name = 'Digifarm', cost = 0.00::DECIMAL, cost_units = 'kes'
            # WHERE id IN
            #     (SELECT sub.id from ishamba.sms_smsrecipient sub WHERE sub.gateway_name='?' AND sub.gateway_msg_id LIKE 'DFid_%' LIMIT 500000);
            # There are only about 3.5M of these and we are simply
            # setting fields to static values, so do all at once.
            logger.debug(f"Annotating {schema_name} Digifarm SMSRecipient objects {bottom_id:,} to {top_id:,}")
            sql = f"UPDATE {schema_name}.sms_smsrecipient " \
                  f"SET gateway_name = '{df_gateway_name}', " \
                  f"cost = 0.00::DECIMAL, " \
                  f"cost_units = 'kes' " \
                  f"WHERE gateway_msg_id LIKE 'DFid_%' AND id BETWEEN {bottom_id} AND {top_id}"
            cursor.execute(sql, )
            bottom_id = top_id + chunk_size
            top_id = bottom_id + chunk_size

        toc1 = time.perf_counter()
        logger.debug(f"Annotated Digifarm SMSRecipient objects in {toc1 - toc0:0.1f} seconds")

        # Next work on extracting cost and cost_units from AfricasTalking messages.
        # Over time, the gateway_msg_id was captured in different ways, using different
        # formats, so it is not as easy to identify them other than if the gateway_name
        # has not been set. Note that we cannot only convert those records with
        # gateway_name = '?' because the costs may not have been extracted from the
        # other records. The query for gateway_name='?' is simply an indicator of completion.
        count = SMSRecipient.objects.filter(gateway_name='?').count()
        if count == 0:
            logger.debug(f"No need to annotate AfricasTalking SMSRecipient objects")
        else:
            chunk_size = 10000
            top_id = max_id
            bottom_id = top_id - chunk_size

            logger.debug(f"Annotating AfricasTalking SMSRecipient objects")

            # Set the gateway_name value for each SMSRecipient record. Also separate the
            # cost and cost_units from SMSRecipient.extra JSON fields from the AT
            # gateway messages (DF does not store costs) into the new top-level fields.
            # Note that many SMSRecipient objects have a null value for gateway_msg_id.
            # Others have a gateway_msg_id stored in their extra field, that starts with '???'.
            # Since only AT sends us delivery status reports, we assume that all null
            # values belong to messages that were sent via the AT gateway. So in this search
            # we try to convert all objects EXCEPT specifically digifarm messages.
            while bottom_id >= 0:
                logger.debug(f"Annotating {schema_name} AfricasTalking SMSRecipient objects {bottom_id:,} to {top_id:,}")
                sql = f"UPDATE {schema_name}.sms_smsrecipient " \
                      f"SET gateway_name = '{at_gateway_name}', " \
                      f"cost = CASE " \
                      f"  WHEN extra ->> 'cost' IS NULL THEN '0.00'::DECIMAL " \
                      f"  WHEN SPLIT_PART(extra->> 'cost', ' ', 2) = '' THEN '0.00'::DECIMAL " \
                      f"  ELSE SPLIT_PART(extra->> 'cost', ' ', 2)::DECIMAL END, " \
                      f"cost_units = CASE " \
                      f"  WHEN extra ->> 'cost' IS NULL THEN 'kes' " \
                      f"  WHEN SPLIT_PART(extra->> 'cost', ' ', 1) = '' THEN 'kes' " \
                      f"  ELSE SPLIT_PART(extra->> 'cost', ' ', 1) END " \
                      f"WHERE gateway_name = '?' AND id BETWEEN {bottom_id} AND {top_id}"
                cursor.execute(sql, )
                top_id = bottom_id
                bottom_id = bottom_id - chunk_size if bottom_id > chunk_size else 0

        toc2 = time.perf_counter()
        logger.debug(f"Annotated AfricasTalking SMSRecipient objects in {toc2 - toc1:0.1f} seconds")

    # Now update all DailyOutgoingSMSSummary objects with new stats
    kenya_id = Border.objects.get(level=0, name="Kenya").id
    # select created from ishamba.sms_smsrecipient order by id desc limit 1;
    earliest_date = SMSRecipient.objects.order_by('pk').only('created').first().created.date()
    today_date = now().date()

    created_count = 0
    updated_count = 0

    # We create distinct objects for each country/day/gateway_name/message_type combination
    for day in daterange(today_date, earliest_date):  # backwards, inclusive of both ends
        logger.debug(f"Summarizing {schema_name} {day}")
        for gateway_name in gateways:
            t1 = time.perf_counter()
            # The base search, annotating the SMSRecipient with other fields that we need
            smsr = SMSRecipient.objects.filter(created__date=day, gateway_name=gateway_name) \
                .annotate(type=F('message__message_type')) \
                .only('id', 'type', 'cost', 'cost_units', 'message_id') \
                .values('id', 'type', 'cost', 'cost_units', 'message_id')
            # Extract the unique message types sent on that day
            types = smsr.order_by('type').distinct('type').values_list('type', flat=True)
            # If no records, in this schema / country / day / gateway_name, try another
            if not types:
                continue
            # Extract the currency/units of the cost field. We are making the assumption
            # that all messages sent via the same gateway in the same country use the
            # same currency for their charges.
            cost_units_record = smsr.filter(cost_units__isnull=False).first()
            cost_units = cost_units_record.get('cost_units').lower() if cost_units_record else '?'
            t2 = time.perf_counter()
            for msg_type in types:
                t3 = time.perf_counter()
                filtered = smsr.filter(type=msg_type)
                count = filtered.count()
                if count == 0:
                    continue
                t4 = time.perf_counter()
                message_ids = list(filtered.order_by('message_id').distinct('message_id').values_list('message_id', flat=True))
                cost_dict = filtered.aggregate(Sum('cost'))
                t5 = time.perf_counter()
                obj, created = DailyOutgoingSMSSummary.objects.update_or_create(
                    date=day,
                    country_id=kenya_id,
                    message_type=msg_type,
                    defaults={
                        'gateway_name': gateway_name,  # The default is '?' so we don't use this in the above search portion
                        'count': count,
                        'cost': cost_dict.get('cost__sum'),
                        'cost_units': cost_units,
                        'extra': {'message_ids': message_ids}
                    }
                )
                t6 = time.perf_counter()
                if created:
                    created_count += 1
                else:
                    updated_count += 1
                logger.debug(f"t2-t1={t2-t1:0.1f}, t4-t3={t4-t3:0.1f}, t5-t4={t5-t4:0.1f}, t6-t5={t6-t5:0.1f}")

    toc3 = time.perf_counter()
    logger.debug(f"Created {created_count} and updated {updated_count} DailyOutgoingSMSSummary "
                 f"objects in {toc3 - toc2:0.1f} seconds")


class Migration(migrations.Migration):
    atomic = False
    dependencies = [
        ('sms', '0052_add_costs_and_gateway_details'),
    ]

    operations = [
        migrations.RunPython(populate_new_fields, reverse_code=migrations.RunPython.noop),
    ]
